- name: Configure the Docker Swarm Cluster
  hosts: all
  become: yes
  vars:
    manager_node: "{{ groups['instance1'][0] }}"
    first_worker: "{{ groups['instance2'][0] }}"
    ansible_python_interpreter: /usr/bin/python3

  tasks:
  # Debug task to help troubleshoot variable issues
  - name: Debug inventory and host information
    debug:
      msg:
        - "Current host: {{ inventory_hostname }}"
        - "Manager node: {{ manager_node }}"
        - "Is manager: {{ inventory_hostname == manager_node }}"
        - "Manager IP: {{ hostvars[manager_node].ansible_host | default(manager_node) }}"
        
  # Docker setup tasks remain the same
  - name: Remove old Docker versions
    apt:
      name:
        - docker
        - docker-engine
        - docker.io
        - containerd
        - runc
      state: absent
      update_cache: yes

  - name: Install dependencies
    apt:
      name:
        - curl
        - ca-certificates
        - git
        - acl
        - python3
        - python3-pip
        - lsb-release
      state: present
      update_cache: yes

  - name: Add Docker's official GPG key and save it in the recommended keyring
    ansible.builtin.shell: |
      curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
    args:
      creates: /usr/share/keyrings/docker-archive-keyring.gpg
    ignore_errors: yes

  - name: Add Docker's repository
    ansible.builtin.shell: |
      echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu jammy stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
    ignore_errors: yes

  - name: Update apt cache
    ansible.builtin.apt:
      update_cache: yes

  - name: Install Docker packages
    apt:
      name:
        - docker-ce
        - docker-ce-cli
        - containerd.io
      state: present
      update_cache: yes

  - name: Install Docker SDK for Python
    apt:
      name: python3-docker
      state: present

  - name: Add users to the Docker group
    user:
      name: "{{ item }}"
      groups: docker
      append: yes
    loop:
      - "{{ ansible_ssh_user }}"
    ignore_errors: yes

  - name: Ensure Docker service is running
    systemd:
      name: docker
      state: started
      enabled: true

  # Initialize swarm on manager
  - name: Initialize Swarm on manager node
    shell: docker swarm init --advertise-addr {{ inventory_hostname }}
    when: inventory_hostname == manager_node
    register: swarm_init
    ignore_errors: yes

  # Debug the init output
  - name: Debug swarm init
    debug:
      var: swarm_init
    when: inventory_hostname == manager_node

  # Get the worker token separately
  - name: Get swarm worker token
    shell: docker swarm join-token -q worker
    register: token_output
    when: inventory_hostname == manager_node

  # Debug the token output
  - name: Debug token output
    debug:
      var: token_output
    when: inventory_hostname == manager_node

  # Set token as a fact on manager
  - name: Set token fact on manager
    set_fact:
      worker_token: "{{ token_output.stdout }}"
    when: inventory_hostname == manager_node

  # Join workers to swarm using the token
  - name: Join workers to swarm
    shell: "docker swarm join --token {{ hostvars[groups['instance1'][0]].worker_token }} {{ groups['instance1'][0] }}:2377"
    when: inventory_hostname != manager_node

  # Copy configuration files 
  - name: Copy stack.yml to manager
    copy:
      src: ../../swarm/stack.yml
      dest: /home/{{ ansible_ssh_user }}/stack.yml
    delegate_to: "{{ manager_node }}"
    run_once: true 
    
  - name: Create DNS directory structure on manager
    file:
      path: /home/{{ ansible_ssh_user }}/dns/zones
      state: directory
      mode: '0755'
    delegate_to: "{{ manager_node }}"
    run_once: true

  - name: Copy Corefile to manager
    copy:
      src: ../roles/networking/dns/Corefile
      dest: /home/{{ ansible_ssh_user }}/dns/Corefile
    delegate_to: "{{ manager_node }}"
    run_once: true

  - name: Copy zone file to manager
    copy:
      src: ../roles/networking/zones/cpplanta.duckdns.org.db
      dest: /home/{{ ansible_ssh_user }}/dns/zones/cpplanta.duckdns.org.db
    delegate_to: "{{ manager_node }}"
    run_once: true

  - name: Update zone file with manager IP
    replace:
      path: /home/{{ ansible_ssh_user }}/dns/zones/cpplanta.duckdns.org.db
      regexp: '10\.0\.1\.10'
      replace: "{{ manager_node }}"  # Using manager_node directly as the IP
    delegate_to: "{{ manager_node }}"
    run_once: true

  # Deploy the stack with better resource allocation
  - name: Deploy the stack on manager (with force update)
    shell: docker stack deploy --with-registry-auth --resolve-image always -c /home/{{ ansible_ssh_user }}/stack.yml CP-Planta
    args:
      chdir: /home/{{ ansible_ssh_user }}
    delegate_to: "{{ manager_node }}"
    run_once: true

  # Install monitoring tools
  - name: Install monitoring tools (htop, ctop, etc)
    apt:
      name:
        - htop
        - iotop
        - sysstat
      state: present
    become: yes

  - name: Add Azure repository key
    apt_key:
      url: https://azlux.fr/repo.gpg.key
      state: present

  - name: Add Azure repository
    apt_repository:
      repo: deb http://packages.azlux.fr/debian/ bullseye main
      state: present

  - name: Install ctop
    apt:
      name: ctop
      state: present
      update_cache: yes
    become: yes

  - name: Wait for 25 seconds to show proper service status
    wait_for:
      timeout: 30

  - name: Show service status
    command: docker service ls
    delegate_to: "{{ manager_node }}"
    run_once: true
    register: service_status
    ignore_errors: yes
  
  - name: Display service status
    debug:
      var: service_status.stdout_lines
    when: service_status is defined